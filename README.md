# Spectra_AI_Anomaly_Detection  
**Prompt-Level Anomaly Detection for AI Safety using Mahalanobis Distance, Ledoitâ€“Wolf Covariance, and Bayesian Inference**

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Framework](https://img.shields.io/badge/Framework-Scikit--learn%20%7C%20NumPy%20%7C%20SciPy-green)
![Status](https://img.shields.io/badge/Status-Completed-success)
![License](https://img.shields.io/badge/License-MIT-orange)

---

## Overview
This project was developed as part of the **Spectra AI Mini Challenge**, focusing on building an **interpretable anomaly detection system** for identifying unsafe or malicious AI prompts.  
It leverages:
- **Mahalanobis Distance** for measuring prompt embedding deviations,  
- **Ledoitâ€“Wolf Covariance Estimation** for robust covariance regularization, and  
- **Bayesian Posterior Probability** for reliability estimation.

---

## Methodology

### 1ï¸âƒ£ Feature Extraction  
Prompt embeddings are obtained from a pre-trained LLM encoder and stored as `.npy` files.  
- Normal and anomalous prompts are represented in 768-dimensional feature space.

### 2ï¸âƒ£ Covariance Regularization  
The **Ledoitâ€“Wolf estimator** is applied to compute a well-conditioned covariance matrix ensuring numerical stability.

### 3ï¸âƒ£ Mahalanobis Distance Computation  
Each embeddingâ€™s deviation from the normal distribution is measured using the Mahalanobis distance.

### 4ï¸âƒ£ Chi-Square Probability Mapping  
Distances are mapped to p-values using a chi-square distribution.  
Prompts with **p < 0.01** are flagged as anomalies.

### 5ï¸âƒ£ Bayesian Posterior Reliability  
Posterior probability `P(malicious | flagged)` is computed to evaluate real-world reliability under various prior assumptions.

---

## Results Summary

| **Metric** | **Value** | **Interpretation** |
|-------------|------------|--------------------|
| Total Prompts | 1080 | Complete dataset size |
| Normal Prompts | 1000 | Safe inputs |
| Anomalous Prompts | 80 | Unsafe/injected inputs |
| Flagged Prompts (p < 0.01) | 88 | 80 anomalies + 8 false positives |
| ROC AUC | **1.000** | Perfect class separation |
| Accuracy | **99.3%** | Excellent model reliability |
| Precision (Anomalies) | 90.9% | Minimal false positives |
| Recall (Anomalies) | 100% | All anomalies detected |
| F1-score | 0.95 | Balanced performance |

---

## Visualizations

### Distribution of Embedding Feature Values
![Embedding Distribution](<img width="713" height="470" alt="Distribution of Embedding Feature Values spectra" src="https://github.com/user-attachments/assets/ac581399-f0a2-4322-ad57-594064dee4ce" />)


---

### Histogram of Mahalanobis Distances
![Mahalanobis Histogram](images/Histogram%20of%20Mahalanobis%20Distances.png)

---

### ROC Curve (Mahalanobis)
![ROC Curve](images/ROC%20Curve%20(Mahalanobis).png)

---

## Key Findings
- The system achieved **ROC AUC = 1.0** and **Accuracy = 99.3%**.  
- **False Positive Rate:** Only 0.8% of safe prompts were wrongly flagged.  
- **True Positive Rate:** 100% of anomalies were correctly detected.  
- **Bayesian reliability** exceeded 93% for realistic priors, showing robustness under real-world conditions.  
- Framework is interpretable, mathematically sound, and deployment-ready.

---

## Project Structure

```
Spectra_AI_Anomaly_Detection/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ embeddings.npy
â”‚   â”œâ”€â”€ normal_embeddings.npy
â”‚   â”œâ”€â”€ anomalous_embeddings.npy
â”‚   â””â”€â”€ labels.npy
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ Distribution of Embedding Feature Values.png
â”‚   â”œâ”€â”€ Histogram of Mahalanobis Distances.png
â”‚   â””â”€â”€ ROC Curve (Mahalanobis).png
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ reference_notes.txt
â”‚
â”œâ”€â”€ Spectra_AI_Mini_Challenge_Atharv_Kulkarni.ipynb
â””â”€â”€ README.md
```

---

## Technologies Used
- **Language:** Python 3.10  
- **Libraries:** NumPy, SciPy, Scikit-learn, Matplotlib  
- **Concepts:** Covariance Regularization, Mahalanobis Distance, Bayesian Probability, Statistical Inference  

---

## How to Run
```bash
# Clone this repository
git clone https://github.com/Kulkarni-ui/Spectra_AI_Anomaly_Detection.git

# Navigate to the directory
cd Spectra_AI_Anomaly_Detection

# Open Jupyter Notebook
jupyter notebook Spectra_AI_Mini_Challenge_Atharv_Kulkarni.ipynb
```

---

## Author
**Atharv Kulkarni**  
B.Tech Artificial Intelligence & Machine Learning  
Symbiosis Institute of Technology, Pune  
ğŸ“§ [Contact via GitHub](https://github.com/Kulkarni-ui)

---

## References
1. Ledoit, O., & Wolf, M. (2004). *Honey, I Shrunk the Sample Covariance Matrix.*  
2. Mahalanobis, P. C. (1936). *On the Generalized Distance in Statistics.*  
3. Bishop, C. M. (2006). *Pattern Recognition and Machine Learning.*  
4. Murphy, K. P. (2012). *Machine Learning: A Probabilistic Perspective.*

---
